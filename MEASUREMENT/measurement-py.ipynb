{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Chapter 2, we begin visualizing data. Python has a variety of excellent plotting libraries. This chapter uses [seaborn](https://seaborn.pydata.org/index.html), which is built on top of [matplotlib](https://matplotlib.org/stable/index.html#). We occassionally leverage matplotlib to customize plots. In seaborn, we use three families of plotting functions, known as \"figure-level\" plots in seaborn terminology. Whenever we use one of these function families, we must specify a \"kind\" of plot, unless the kind we want to use is the default. The table below summarizes the families of plotting functions and the kinds of plots used in this chapter. Seaborn also has more specific, \"axes-level,\" plotting functions, such as `histplot` and `scatterplot`. Axes-level plots are particularly useful for creating sub-plots. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center\">\n",
    "\n",
    "<center>\n",
    "\n",
    "| Family | Kind |\n",
    "|----------|----------|\n",
    "| relplot   | scatter (default), line   |\n",
    "| displot | hist (default), kde |\n",
    "| catplot  | bar, box  |\n",
    "\n",
    "</center>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3.1: Measuring Civilian Victimization during Wartime {-}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries used in chapter with conventinal aliases\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import data\n",
    "afghan = pd.read_csv('afghan.csv')\n",
    "\n",
    "# summarize variables of interest\n",
    "afghan['age'].describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "afghan['educ.years'].describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "afghan['employed'].describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "afghan['income'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "afghan['income'].value_counts(sort=False, dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert income to a categorical variable and specify levels\n",
    "afghan['income'] = afghan['income'].astype('category').cat.reorder_categories(\n",
    "    ['less than 2,000', '2,001-10,000', '10,001-20,000', '20,001-30,000', \n",
    "     'over 30,000']\n",
    ")\n",
    "\n",
    "afghan['income'].value_counts(sort=False, dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(afghan['violent.exp.ISAF'], afghan['violent.exp.taliban'],\n",
    "            rownames=['ISAF'], colnames=['Taliban'], normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3.2: Handling Missing Data in Pandas {-}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print income data for first 10 respondents\n",
    "afghan['income'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indicate whether respondents' income is missing\n",
    "afghan['income'].isnull().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count of missing values\n",
    "afghan['income'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# proportion of missing values\n",
    "afghan['income'].isnull().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.Series([1, 2, 3, np.nan])\n",
    "\n",
    "# pandas ignores missing values by default\n",
    "x.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can override the default behavior\n",
    "x.mean(skipna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pandas `crosstab` method does not have an argument for including missing values in a contingency table. Instead, we can use the `fillna` method to supply a name for the missing values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(afghan['violent.exp.ISAF'].fillna('Nonresponse'),\n",
    "            afghan['violent.exp.taliban'].fillna('Nonresponse'), \n",
    "            rownames=['ISAF'], colnames=['Taliban'], normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# listwise deletion\n",
    "afghan_sub = afghan.dropna()\n",
    "\n",
    "afghan_sub.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "afghan['income'].dropna().shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3.3: Visualizing the Univariate Distribution {-}\n",
    "\n",
    "### Section 3.3.1: Bar Plot {-}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a vector of proportions to plot\n",
    "ISAF_ptable = (afghan['violent.exp.ISAF'].\n",
    "               value_counts(normalize=True, dropna=False).reset_index())\n",
    "\n",
    "ISAF_ptable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a response column for plotting convenience\n",
    "ISAF_ptable['response'] = ['No harm', 'Harm', 'Nonresponse']\n",
    "\n",
    "# plot using the catplot family and kind='bar'\n",
    "sns.catplot(\n",
    "    data=ISAF_ptable, x='response', y='proportion', color='gray',\n",
    "    kind='bar', estimator=sum, height=4, aspect=1.5 \n",
    ").set(title='Civilian victimization by the ISAF', \n",
    "      xlabel='Response category', ylabel='Proportion of the respondents',\n",
    "      ylim=(0, 0.7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice, we use `estimator=sum` because seaborn bar plots aggregate the data by a given function. The default aggregation function is `mean`. Since we have already calculated proportions, we can use `sum` to ensure there is no further aggregation. Another strategy for creating the bar plot is to use the mean aggregation directly on the original data frame categories. \n",
    "\n",
    "Additionally, we set the height and aspect ratios directly. The default height is 5 inches for seaborn figure-level plots, and the default aspect ratio is 1. The aspect ratio is the ratio of the width to the height. Therefore, the default width is 5 inches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeat the same for the Taliban\n",
    "Taliban_ptable = (afghan['violent.exp.taliban'].\n",
    "                   value_counts(normalize=True, dropna=False).reset_index())\n",
    "\n",
    "Taliban_ptable['response'] = ['No harm', 'Harm', 'Nonresponse']\n",
    "\n",
    "sns.catplot(\n",
    "    data=Taliban_ptable, x='response', y='proportion', color='gray',\n",
    "    kind='bar', estimator=sum, height=4, aspect=1.5\n",
    ").set(title='Civilian victimization by the Taliban', \n",
    "      xlabel='Response category', ylabel='Proportion of the respondents',\n",
    "      ylim=(0, 0.7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 3.3.2: Histogram {-}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(\n",
    "    data=afghan, x='age', stat='density', color='gray', \n",
    "    height=4, aspect=1.5\n",
    ").set(title=\"Distribution of respondents' age\", xlabel='Age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram of education\n",
    "# use binrange and binwidth to control the bins\n",
    "sns.displot(\n",
    "    data=afghan, x='educ.years', stat='density', color='gray', \n",
    "    binrange=(-0.5, 18.5), binwidth=1, height=4, aspect=1.5\n",
    ").set(title=\"Distribution of respondents' education\", \n",
    "      xlabel='Years of education')\n",
    "\n",
    "# add a vertical line representing the median\n",
    "plt.axvline(x=afghan['educ.years'].median(), color='black', linestyle='--')\n",
    "\n",
    "# add a text label for the median\n",
    "plt.text(x=1.5, y=0.5, s='median')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 3.3.3: Box Plot {-}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert province to a categorical variable\n",
    "# not necessary for plotting, but useful for other analyses\n",
    "afghan['province'] = afghan['province'].astype('category')\n",
    "\n",
    "sns.catplot(\n",
    "    data=afghan, x='province', y='educ.years', kind='box', color='gray',\n",
    "    height=4, aspect=1.5\n",
    ").set(title='Education by province', xlabel='', ylabel='Years of education')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "afghan.groupby('province')['violent.exp.taliban'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "afghan.groupby('province')['violent.exp.ISAF'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 3.3.4: Saving Plots {-}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Save via point-and-click in IDE\n",
    "\n",
    "# Option 2: Run plot code plus plt.savefig()\n",
    "\n",
    "sns.catplot(\n",
    "    data=afghan, x='province', y='educ.years', kind='box', color='gray',\n",
    "    height=4, aspect=1.5\n",
    ").set(title='Education by province', xlabel='', ylabel='Years of education')\n",
    "\n",
    "plt.savefig('education-by-province.png', bbox_inches='tight')\n",
    "\n",
    "plt.close() # preventing plot from re-displaying"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3.4: Survey Sampling {-}\n",
    "\n",
    "### Section 3.4.1: The Role of Randomization {-}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load village data \n",
    "afghan_village = pd.read_csv('afghan-village.csv')\n",
    "\n",
    "# add a more descriptive variable for survey status to aid plotting \n",
    "afghan_village['village_surveyed_desc'] = (\n",
    "    np.where(afghan_village['village.surveyed']==1, 'Sampled', 'Nonsampled')\n",
    "    )\n",
    "\n",
    "# boxplots for altitude \n",
    "sns.catplot(\n",
    "    data=afghan_village, x='village_surveyed_desc', y='altitude', kind='box',\n",
    "    color='gray', height=4, aspect=1.5\n",
    ").set(ylabel='Altitude (meters)', xlabel='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the natural log of population to the data frame\n",
    "afghan_village['log_pop'] = np.log(afghan_village['population'])\n",
    "\n",
    "# boxplots for log population \n",
    "sns.catplot(\n",
    "    data=afghan_village, x='village_surveyed_desc', y='log_pop', kind='box',\n",
    "    color='gray', height=4, aspect=1.5\n",
    ").set(ylabel='Log population', xlabel='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 3.4.2: Nonresponse and Other Sources of Bias {-}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "afghan.groupby('province')['violent.exp.taliban'].apply(\n",
    "    lambda x: x.isnull().mean()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "afghan.groupby('province')['violent.exp.ISAF'].apply(\n",
    "    lambda x: x.isnull().mean()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(afghan['list.response'][afghan['list.group'] == 'ISAF'].mean() - \n",
    " afghan['list.response'][afghan['list.group'] == 'control'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "afghan['list.group'] = (\n",
    "    afghan['list.group'].astype('category').cat.reorder_categories(\n",
    "        ['control', 'ISAF', 'taliban'])\n",
    ")\n",
    "\n",
    "pd.crosstab(afghan['list.response'], afghan['list.group'],\n",
    "            colnames=['group'], rownames=['response'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3.5: Measuring Political Polarization {-}\n",
    "\n",
    "## Section 3.6: Summarizing Bivariate Relationships {-}\n",
    "\n",
    "### Section 3.6.1: Scatter Plot {-}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "congress = pd.read_csv('congress.csv')\n",
    "\n",
    "congress.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "congress.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store some plotting parameters for reuse\n",
    "xlab='Economic liberalism/conservatism'\n",
    "ylab='Racial liberalism/conservatism'\n",
    "lim=(-1.5, 1.5)\n",
    "\n",
    "# scatterplot for 80th congress\n",
    "sns.relplot(\n",
    "    data=congress.loc[(congress['congress'] == 80) & \n",
    "                      (congress['party'] != 'Other')],\n",
    "    x='dwnom1', y='dwnom2', hue='party', style='party', palette=['b', 'r'],\n",
    "    height=4, aspect=1.5\n",
    ").set(title='80th Congress', xlabel=xlab, ylabel=ylab, xlim=lim, ylim=lim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatterplot for 112th congress\n",
    "sns.relplot(\n",
    "    data=congress.loc[(congress['congress'] == 112) & \n",
    "                      (congress['party'] != 'Other')],\n",
    "    x='dwnom1', y='dwnom2', hue='party', style='party', palette=['b', 'r'],\n",
    "    height=4, aspect=1.5\n",
    ").set(title='112th Congress', xlabel=xlab, ylabel=ylab, xlim=lim, ylim=lim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the median for combinations of party and congress\n",
    "dwn1_med = (congress.loc[congress.party != 'Other'].\n",
    "            groupby(['party', 'congress'])['dwnom1'].median().reset_index())\n",
    "\n",
    "sns.relplot(\n",
    "    data=dwn1_med, x='congress', y='dwnom1', hue='party', kind='line',\n",
    "    palette=['b', 'r'], height=4, aspect=1.5\n",
    ").set(ylim=(-1, 1), xlabel='Congress', \n",
    "      ylabel='DW-NOMINATE score (1st dimension)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 3.6.2: Correlation {-}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gini = pd.read_csv('USGini.csv')\n",
    "\n",
    "'''\n",
    "Calculate the difference between the Republican and Democratic medians.\n",
    "\n",
    "pandas will try to align indexes in conducting vector arithmetic. Therefore, \n",
    "it is best to reset the index and drop the old one so that the indexes are the\n",
    "same. An alternative is to use numpy arrays. \n",
    "'''\n",
    "med_diff = (\n",
    "    dwn1_med['dwnom1'][dwn1_med.party=='Republican'].reset_index(drop=True) - \n",
    "    dwn1_med['dwnom1'][dwn1_med.party=='Democrat'].reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# time series plot for partisan differences \n",
    "# notice, we can feed x and y directly\n",
    "sns.relplot(\n",
    "    x=np.arange(1947.5, 2012.5, step=2), y=med_diff, kind='line', \n",
    "    color='black', height=4, aspect=1.5\n",
    ").set(title='Political Polarization', xlabel='Year',\n",
    "      ylabel='Republican median - Democratic median')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time-series plot for Gini coefficient\n",
    "sns.relplot(\n",
    "    data=gini, x='year', y='gini', kind='line', color='black',\n",
    "    height=4, aspect=1.5\n",
    ").set(title='Income Inequality', ylabel='Gini coefficient', xlabel='Year')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To correlate the partisan difference with the Gini coefficient, we need to select every other observation for the Gini starting with the second observation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(gini['gini'].iloc[np.arange(1, gini.shape[0], step=2)].\n",
    " reset_index(drop=True).corr(med_diff))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 3.6.3: Quantile-Quantile Plot {-}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dem112 = congress.loc[(congress['congress'] == 112) & \n",
    "                      (congress['party'] == 'Democrat')]\n",
    "\n",
    "rep112 = congress.loc[(congress['congress'] == 112) & \n",
    "                      (congress['party'] == 'Republican')]\n",
    "\n",
    "sns.displot(\n",
    "    data=dem112, x='dwnom2', stat='density', color='gray',\n",
    "    height=4, aspect=1.5\n",
    ").set(title='Democrats', xlabel='Racial liberalism/conservatism dimension',\n",
    "      xlim=(-1.5, 1.5), ylim=(0, 1.75))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(\n",
    "    data=rep112, x='dwnom2', stat='density', color='gray',\n",
    "    height=4, aspect=1.5\n",
    ").set(title='Republicans', xlabel='Racial liberalism/conservatism dimension',\n",
    "      xlim=(-1.5, 1.5), ylim=(0, 1.75))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seaborn does not have a built-in function for Q-Q plots. However, we can \n",
    "create a scatterplot of the quantiles of two variables. The quantiles we plot need to be the same length. Below, we calculate and plot percentiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantiles = np.linspace(0, 1, 101)\n",
    "\n",
    "demq = dem112['dwnom2'].quantile(quantiles)\n",
    "repq = rep112['dwnom2'].quantile(quantiles)\n",
    "\n",
    "sns.relplot(\n",
    "    x = demq, y = repq, height=4, aspect=1.5\n",
    ").set(xlabel='Democrats', ylabel='Republicans',\n",
    "      title='Racial liberalism/conservatism dimension',\n",
    "      ylim=(-1.5, 1.5), xlim=(-1.5, 1.5))\n",
    "\n",
    "plt.gca().axline((0, 0), slope=1, color='red', linestyle='--')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3.7: Clustering {-}\n",
    "\n",
    "Before implementing clustering with the k-Means algorithm, we discuss numpy arrays and objects in Python, both of which are important for many Python modeling libraries.\n",
    "\n",
    "### Section 3.7.1: Numpy Arrays {-}\n",
    "\n",
    "Thus far, we have used the [numpy](https://numpy.org/doc/stable/index.html) library for specific tasks, such as vectorized if-else statements using `np.where()` and log transformations using `np.log()`, but we have primarily relied on pandas for our analytical infrastructure. Having at least a high-level understanding of how numpy works is important for effective data analytics in Python. Indeed, pandas is built on top of numpy. While Python modeling libraries often work well with pandas, they occasionally work better with numpy, and many modeling outputs are numpy objects, as we will see in 3.7.3. \n",
    "\n",
    "The fundamental numpy data structure is the N-dimensional array, known as the `ndarray`. For those coming from an R background, a one-dimensional numpy array is similar to a vector in R. There are a number of ways to create a numpy vector, depending on the analytical context. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-dimensional arrays as vectors\n",
    "\n",
    "# create a one-dimensional numpy array\n",
    "\n",
    "## from a list\n",
    "x = np.array([10, 20, 30, 40, 50])\n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## from a sequence\n",
    "y = np.arange(10, 60, 10)\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## from random draws from a uniform distribution between 50 and 100\n",
    "z = np.random.uniform(low=50, high=100, size=10)\n",
    "\n",
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indexing and slicing numpy arrays is similar to indexing and slicing Python lists. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the first observation from z\n",
    "## recall, Python uses zero-based indexing\n",
    "z[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the first five observations from z\n",
    "## recall, Python uses \"up to but not including\" slicing semantics\n",
    "z[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the fifth observation onward\n",
    "z[4:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In base Python, we need to use for loops to perform operations on each element of a list. Numpy, by contrast, enables vectorized computations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conduct vectorized arithmetic: multiply each element by .25\n",
    "z * .25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conduct conditional vectorized arithmetic\n",
    "## if an element is above 75, multiply by .25; otherwise, multiply by .75\n",
    "np.where(z > 75, z * .25, z * .75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the sum of the elements\n",
    "z.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the mean of the elements\n",
    "z.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two-dimensional numpy arrays can be thought of as matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a two-dimensional numpy array from a range\n",
    "mat = np.arange(0, 10).reshape(5, 2)\n",
    "\n",
    "mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the first row\n",
    "mat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the second column\n",
    "mat[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the first two rows and the second column\n",
    "mat[0:2, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the sum of the columns\n",
    "mat.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the mean of the rows\n",
    "mat.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the standard deviation of the columns\n",
    "mat.std(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A matrix generally must have the same data type for all elements. A data frame can have different data types for each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'x': ['a', 'b', 'c'], 'y': [1, 2, 3]})\n",
    "\n",
    "df.dtypes # contains a string and an integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(df).dtype # produces a dtype 'O' for object; in other words, a string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 3.7.2: Objects in Python {-}\n",
    "\n",
    "In Python, it is said that \"everything is an object.\" Python makes heavy use of object oriented programming (OOP), a programming paradigm that involves grouping code and data together into objects. In OOP, an object is created from a template called a \"class.\" The data associated with objects are generally called attributes, and the functions are called methods. Libraries like pandas, numpy, and seaborn are designed so that we do not have to worry too much about OOP particulars. Still, it is important to recognize that we are working with objects of specific classes that have attributes and methods. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the object class \n",
    "type(congress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# review an object's methods and attributes; print the first 15\n",
    "dir(congress)[0:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a list comprehension to view the non-private attributes and methods\n",
    "[item for item in dir(congress) if not item.startswith('_')][0:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the data frame's value_counts \"method\"\n",
    "congress['party'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# review the data frame's shape \"attribute\"\n",
    "congress.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we will see in 3.7.3, some important modeling libraries in Python, such as scikit-learn, rely on a more conventional OOP workflow. In such a workflow, one generally follows a few key steps: \n",
    "\n",
    "- Select a class. \n",
    "- Instantiate an object of the class and set desired parameters. \n",
    "- Use the object's methods to perform operations on data. \n",
    "- Extract results from the object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 3.7.3: The k-Means Algorithm {-}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "dwnom80 = congress.loc[congress['congress']==80, ['dwnom1', 'dwnom2']].copy()\n",
    "\n",
    "dwnom112 = congress.loc[congress['congress']==112, ['dwnom1', 'dwnom2']].copy()\n",
    "\n",
    "# kmeans with two clusters\n",
    "\n",
    "## instantiate the model with parameters\n",
    "k80two = KMeans(n_clusters=2, n_init=5)\n",
    "k112two = KMeans(n_clusters=2, n_init=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are working on Windows, you may get a warning about about memory \n",
    "leakage associated with using KMeans on Windows. The warning will likely\n",
    "recommend setting the environmental variable OPM_NUM_THREADS to a certain value. To do so, follow these steps: \n",
    "\n",
    "- (1) Click on the Windows Search button\n",
    "- (2) Type \"Edit the system environment variables\"\n",
    "- (3) Select \"Environment Variables\"\n",
    "- (4) Click \"New\" under \"User variables for your_username\"\n",
    "- (5) Enter \"OMP_NUM_THREADS\" for the variable name and '1' or the number recommended in the warning for the variable value\n",
    "- (6) Click \"OK\" and close the windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## fit the model to the data\n",
    "k80two.fit(dwnom80)\n",
    "k112two.fit(dwnom112)\n",
    "\n",
    "## predict the clusters\n",
    "k80two_labels = k80two.predict(dwnom80)\n",
    "k112two_labels = k112two.predict(dwnom112)\n",
    "\n",
    "type(k80two_labels) # numpy.ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a list comprehension to view the non-private methods and attributes\n",
    "[item for item in dir(k80two) if not item.startswith('_')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final centroids\n",
    "k80two.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k112two.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(k112two.cluster_centers_) # numpy.ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of observations for each cluster by party\n",
    "pd.crosstab(congress['party'][congress.congress == 80], \n",
    "            k80two_labels, colnames=['cluster'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(congress['party'][congress.congress == 112],\n",
    "            k112two_labels, colnames=['cluster'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k means with four clusters\n",
    "k80four = KMeans(n_clusters=4, n_init=5)\n",
    "k112four = KMeans(n_clusters=4, n_init=5)\n",
    "\n",
    "k80four.fit(dwnom80)\n",
    "k112four.fit(dwnom112)\n",
    "\n",
    "k80four_labels = k80four.predict(dwnom80)\n",
    "k112four_labels = k112four.predict(dwnom112)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the centroids over the clusters using subplots\n",
    "fix, ax = plt.subplots(1,1)\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=dwnom80, x='dwnom1', y='dwnom2', hue=k80four_labels, legend=False,\n",
    "    palette='pastel', ax=ax,\n",
    "    ).set(title='80th Congress', xlabel=xlab, ylabel=ylab, xlim=lim, ylim=lim)\n",
    "\n",
    "sns.scatterplot(\n",
    "    x=k80four.cluster_centers_[:,0], y=k80four.cluster_centers_[:,1], \n",
    "    legend=False, color='black', s=100, marker='X', ax=ax,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeat for 112th congress\n",
    "fix, ax = plt.subplots(1,1)\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=dwnom112, x='dwnom1', y='dwnom2', hue=k112four_labels, legend=False,\n",
    "    palette='pastel', ax=ax,\n",
    "    ).set(title='112th Congress', xlabel=xlab, ylabel=ylab, xlim=lim, ylim=lim)\n",
    "\n",
    "sns.scatterplot(\n",
    "    x=k112four.cluster_centers_[:,0], y=k112four.cluster_centers_[:,1], \n",
    "    legend=False, color='black', s=100, marker='X', ax=ax,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "Kosuke Imai"
   },
   {
    "name": "Python code by Jeff Allen"
   }
  ],
  "date": "First Printing",
  "kernelspec": {
   "display_name": "qss",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "title": "Python Code for QSS Chapter 3: Measurement"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
